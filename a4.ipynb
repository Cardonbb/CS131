{"cells":[{"cell_type":"code","execution_count":1,"id":"104d404e-840b-4426-b0a6-ffba6edb0617","metadata":{"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["25/04/29 00:39:09 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]}],"source":["from pyspark.sql import SparkSession\n","from time import time\n","import matplotlib.pyplot as plt\n","\n","spark = SparkSession.builder.appName(\"A4SparkSQLApp\").getOrCreate()\n","\n","\n","file = \"gs://dataproc-staging-us-central1-493734936652-dwhhoqnb/2019-01-h1.csv\"\n","\n","df = spark.read.csv(file, header=True, inferSchema=True)\n"]},{"cell_type":"code","execution_count":4,"id":"81253e51-fee2-4924-ae83-123f308a8d11","metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["#1\n","df = df.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\")\n","df.show(10)"]},{"cell_type":"code","execution_count":5,"id":"2091e9ac-312a-4cf6-9d77-47b46c53bac3","metadata":{},"outputs":[],"source":["#2\n","trainDF, testDF = df.randomSplit([.8,.2],seed=42)"]},{"cell_type":"code","execution_count":11,"id":"41c75d7b","metadata":{},"outputs":[],"source":["#3 \n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n","\n","vecAssembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"],\n","    outputCol=\"features\")\n","dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\")\n","dt = dt.setMaxBins(128)"]},{"cell_type":"code","execution_count":12,"id":"32d3cc5d","metadata":{},"outputs":[],"source":["#4\n","from pyspark.ml import Pipeline\n","\n","pipeline = Pipeline(stages=[vecAssembler, dt])\n"]},{"cell_type":"code","execution_count":13,"id":"eb90ac63","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#5\n","model = pipeline.fit(trainDF)"]},{"cell_type":"code","execution_count":14,"id":"6e4094ce","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 32:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n","+---------------+------------+------------+------------+------------------+\n","|            0.0|         4.0|         4.0|         4.3| 24.03192497663894|\n","|            0.0|         4.0|        33.0|       17.75|19.232590849471666|\n","|            0.0|         4.0|        68.0|        15.8| 17.01111277291278|\n","|            0.0|         4.0|        79.0|        9.75| 17.01111277291278|\n","|            0.0|         4.0|       125.0|         9.3| 17.01111277291278|\n","|            0.0|         4.0|       170.0|       11.15| 17.01111277291278|\n","|            0.0|         7.0|         7.0|        0.31|19.232590849471666|\n","|            0.0|         7.0|         7.0|         6.3|19.232590849471666|\n","|            0.0|         7.0|       112.0|        16.8| 17.01111277291278|\n","|            0.0|         7.0|       138.0|        10.8| 17.01111277291278|\n","+---------------+------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# 6\n","predict = model.transform(testDF)\n","\n","predict.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"prediction\").show(10)\n"]},{"cell_type":"code","execution_count":18,"id":"080f2f9f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 35:=============================>                            (2 + 2) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["RMSE is 24.620677651840293\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 35:===========================================>              (3 + 1) / 4]\r","\r","                                                                                \r"]}],"source":["#7\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","evaluator = RegressionEvaluator(\n","    labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\"\n",")\n","rmse = evaluator.evaluate(predict)\n","print(f\"RMSE is {rmse}\")"]},{"cell_type":"code","execution_count":null,"id":"942ed3f0","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}